<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html dir="ltr" lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
  <meta content="Synthesizer,1937,1950s,1958,1960s,1964,1968,1978,1980s,1983,1989" name="keywords" />
  <link href="../../favicon.ico" rel="shortcut icon" />
  <link href="../../wp/w/Wikipedia_Text_of_the_GNU_Free_Documentation_License.htm" rel="copyright" />
  <title>Synthesizer</title>
  <style media="screen,projection" type="text/css">/*<![CDATA[*/ @import "../../css/wp-monobook-main.css"; /*]]>*/</style>
  <link href="../../css/wp-commonPrint.css" media="print" rel="stylesheet" type="text/css" />
  <!--[if lt IE 5.5000]><style type="text/css">@import "../../css/IE50Fixes.css";</style><![endif]-->
  <!--[if IE 5.5000]><style type="text/css">@import "../../css/IE55Fixes.css";</style><![endif]-->
  <!--[if IE 6]><style type="text/css">@import "../../css/IE60Fixes.css";</style><![endif]-->
  <!--[if IE 7]><style type="text/css">@import "../../css/IE70Fixes.css";</style><![endif]-->
  <!--[if lt IE 7]><script type="text/javascript" src="../../js/IEFixes.js"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->
  <script type="text/javascript">
			var skin = "monobook";
			var stylepath = "/skins-1.5";

			var wgArticlePath = "/wiki/$1";
			var wgScriptPath = "/w";
			var wgServer = "http://en.wikipedia.org";
                        
			var wgCanonicalNamespace = "";
			var wgNamespaceNumber = 0;
			var wgPageName = "Synthesizer";
			var wgTitle = "Synthesizer";
			var wgArticleId = 27704;
			var wgIsArticle = true;
                        
			var wgUserName = null;
			var wgUserLanguage = "en";
			var wgContentLanguage = "en";
		</script>
  <script src="../../js/wikibits.js" type="text/javascript"><!-- wikibits js --></script>
  <script src="../../js/wp.js" type="text/javascript"><!-- site js --></script>
  <style type="text/css">/*<![CDATA[*/
@import "../../css/wp-common.css";
@import "../../css/wp-monobook.css";
@import "../../css/wp.css";
/*]]>*/</style>
  <!-- Head Scripts -->
 </head>
 <body class="mediawiki ns-0 ltr page-Synthesizer">
  <div id="globalWrapper">
   <div id="column-content">
    <div id="content"><a id="top" name="top"></a><h1 class="firstHeading">Synthesizer</h1>
     <div id="bodyContent">
      <h3 id="siteSub"><a href="../../index.htm">2007 Schools Wikipedia Selection</a>. Related subjects: <a href="../index/subject.Music.Musical_Instruments.htm">Musical Instruments</a></h3>
      <!-- start content -->
      <p>A <b>synthesizer</b> (or <b>synthesiser</b>) is an <!--del_lnk--> electronic musical instrument designed to produce electronically generated sound, using techniques such as <!--del_lnk--> additive, <!--del_lnk--> subtractive, <!--del_lnk--> FM, <!--del_lnk--> physical modelling <!--del_lnk--> synthesis, or <!--del_lnk--> phase distortion.<p>Synthesizers create sounds through direct manipulation of electrical voltages (as in <!--del_lnk--> analog synthesizers), mathematical manipulation of <!--del_lnk--> discrete values using computers (as in <!--del_lnk--> software synthesizers), or by a combination of both methods. In the final stage of the synthesizer, electrical voltages generated by the synthesizer cause vibrations in the diaphragms of <!--del_lnk--> loudspeakers, <!--del_lnk--> headphones, etc. This synthesized sound is contrasted with recording of natural sound, where the mechanical energy of a sound wave is transformed into a signal which will then be converted back to mechanical energy on playback (though <!--del_lnk--> sampling synthesizers significantly blur this distinction).<p>Synthesizers typically have a <!--del_lnk--> keyboard which provides the human interface to the instrument and are often thought of as keyboard instruments. However, a synthesizer&#39;s human interface does not necessarily have to be a keyboard, nor does a synthesizer strictly need to be playable by a human. Different <!--del_lnk--> fingerboard synthesizer or ribbon controlled synthesizers have also been developed. (See <!--del_lnk--> sound module.)<p>The term &quot;<a href="../../wp/s/Speech_synthesis.htm" title="Speech synthesis">speech synthesizer</a>&quot; is also used in electronic <!--del_lnk--> speech processing, often in connection with <!--del_lnk--> vocoders.<p>
       <script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script><a id="Sound_basics" name="Sound_basics"></a><h2> <span class="mw-headline">Sound basics</span></h2>
      <p>When natural tonal instruments&#39; sounds are analyzed in the <!--del_lnk--> frequency domain, the <!--del_lnk--> spectra of tonal instruments exhibit amplitude peaks at the <!--del_lnk--> harmonics. These harmonics&#39; frequencies are primarily located close to the integer multiples of the tone&#39;s <!--del_lnk--> fundamental frequency.<p><!--del_lnk--> Percussives and rasps usually lack harmonics, and exhibit spectra that are comprised mainly of noise shaped by the <!--del_lnk--> resonant frequencies of the structures that produce the sounds. The resonant properties of the instruments (the spectral peaks of which are also referred to as <!--del_lnk--> formants) also shape the spectra of string, wind, voice and other natural instruments.<p>In most conventional synthesizers, for purposes of resynthesis, recordings of real instruments can be thought to be composed of several components.<p>These component sounds represent the acoustic responses of different parts of the instrument, the sounds produced by the instrument during different parts of a performance, or the behaviour of the instrument under different playing conditions (pitch, intensity of playing, fingering, etc.) The distinctive timbre, intonation and attack of a real instrument can therefore be created by mixing together these components in such a way as resembles the natural behaviour of the real instrument. Nomenclature varies by synthesizer methodology and manufacturer, but the components are often referred to as <!--del_lnk--> oscillators or <!--del_lnk--> partials. A higher fidelity reproduction of a natural instrument can typically be achieved using more oscillators, but increased computational power and human programming is required, and most synthesizers use between one and four oscillators by default.<div class="thumb tright">
       <div style="width:215px;"><a class="internal" href="../../images/220/22080.png.htm" title="Schematic of ADSR"><img alt="Schematic of ADSR" height="87" longdesc="/wiki/Image:Adsr_graph.png" src="../../images/220/22080.png" width="213" /></a><div class="thumbcaption">Schematic of <!--del_lnk--> ADSR</div>
       </div>
      </div>
      <p>One of the most important parts of any sound is its amplitude envelope. This envelope determines whether the sound is percussive, like a snare drum, or persistent, like a violin string. Most often, this shaping of the sound&#39;s amplitude profile is realized with an &quot;<!--del_lnk--> ADSR&quot; (Attack Decay Sustain Release) envelope model applied to control oscillator volumes. Apart from Sustain, each of these stages is modeled by a change in volume (typically exponential).<ul>
       <li><b>Attack time</b> is the time taken for initial run-up of the sound level from nil to 100%.<li><b>Decay time</b> is the time taken for the subsequent run down from 100% to the designated Sustain level.<li><b>Sustain level</b>, the third stage, is the steady volume produced when a key is held down.<li><b>Release time</b> is the time taken for the sound to decay from the Sustain level to nil when the key is released. If a key is released during the Attack or Decay stage, the Sustain phase is usually skipped. Similarly, a Sustain level of zero will produce a more-or-less piano-like (or percussive) envelope, with no continuous steady level, even when a key is held. Exponential rates are commonly used because they closely model real physical vibrations, which usually rise or <!--del_lnk--> decay exponentially.</ul>
      <p>Although the oscillations in real instruments also change frequency, most instruments can be modeled well without this refinement. This refinement is necessary to generate a <!--del_lnk--> vibrato.<p><a id="Overview_of_popular_synthesis_methods" name="Overview_of_popular_synthesis_methods"></a><h2> <span class="mw-headline">Overview of popular synthesis methods</span></h2>
      <p>Subtractive synthesizers use a simple acoustic model that assumes an instrument can be approximated by a simple signal generator (producing <!--del_lnk--> sawtooth waves, <!--del_lnk--> square waves, etc...) followed by a <!--del_lnk--> filter which represents the frequency-dependent losses and resonances in the instrument body. For reasons of simplicity and economy, these filters are typically low-order lowpass filters. The combination of simple modulation routings (such as <!--del_lnk--> pulse width modulation and <!--del_lnk--> oscillator sync), along with the physically unrealistic lowpass filters, is responsible for the &quot;classic synthesizer&quot; sound commonly associated with &quot;analog synthesis&quot; and often mistakenly used when referring to software synthesizers using subtractive synthesis. Although <!--del_lnk--> physical modeling synthesis, synthesis wherein the sound is generated according to the physics of the instrument, has superseded subtractive synthesis for accurately reproducing natural instrument timbres, the subtractive synthesis paradigm is still ubiquitous in synthesizers with most modern designs still offering low-order lowpass or bandpass filters following the oscillator stage.<p>One of the newest systems to evolve inside music synthesis is physical modelling. This involves taking up models of components of musical objects and creating systems which define action, filters, envelopes and other parameters over time. The definition of such instruments is virtually limitless, as one can combine any given models available with any amount of sources of modulation in terms of pitch, frequency and contour. For example, the model of a violin with characteristics of a pedal steel guitar and perhaps the action of piano hammer ... physical modelling on computers gets better and faster with higher processing ..<p>One of the easiest synthesis systems is to record a real instrument as a digitized waveform, and then play back its recordings at different speeds to produce different tones. This is the technique used in &quot;sampling&quot;. Most samplers designate a part of the sample for each component of the ADSR envelope, and then repeat that section while changing the volume for that segment of the envelope. This lets the sampler have a persuasively different envelope using the same note.. <i>See also: <!--del_lnk--> Sample-based synthesis.</i><p><a id="Synthesizer_basics" name="Synthesizer_basics"></a><h2> <span class="mw-headline">Synthesizer basics</span></h2>
      <p>There are two major kinds of synthesizers, <!--del_lnk--> analog and <!--del_lnk--> digital.<p>There are also many different kinds of synthesis methods, each applicable to both analog and digital synthesizers. These techniques tend to be mathematically related, especially frequency modulation and phase modulation.<ul>
       <li><!--del_lnk--> Subtractive synthesis<li><!--del_lnk--> Additive synthesis<li><!--del_lnk--> Granular synthesis<li><!--del_lnk--> Wavetable synthesis<li><!--del_lnk--> Frequency modulation synthesis<li><!--del_lnk--> Phase distortion synthesis<li><!--del_lnk--> Physical modelling synthesis<li><!--del_lnk--> Sampling<li><!--del_lnk--> Subharmonic synthesis</ul>
      <p><a id="The_start_of_the_analogue_synthesizer_era" name="The_start_of_the_analogue_synthesizer_era"></a><h2> <span class="mw-headline">The start of the analogue synthesizer era</span></h2>
      <p>The first electric musical synthesizer was invented in 1876 by <!--del_lnk--> Elisha Gray <!--del_lnk--> , who was also an independent inventor of the <a href="../../wp/t/Telephone.htm" title="Telephone">telephone</a>. The &quot;Musical Telegraph&quot; was a chance by-product of his telephone technology.<p>Gray accidentally discovered that he could control sound from a self vibrating electromagnetic circuit and in doing so invented a basic single note oscillator. The Musical Telegraph used steel reeds whose oscillations were created and transmitted, over a telephone line, by electromagnets. Gray also built a simple loudspeaker device in later models consisting of a vibrating diaphragm in a magnetic field to make the oscillator audible.<p>Other early synthesizers used technology derived from electronic <!--del_lnk--> analog computers, laboratory test equipment, and early <!--del_lnk--> electronic musical instruments. <!--del_lnk--> Ivor Darreg created his <!--del_lnk--> microtonal &#39;Electronic Keyboard Oboe&#39; in <!--del_lnk--> 1937. Another one of the early synthesizers was the <!--del_lnk--> ANS synthesizer, a machine that was constructed by the Russian scientist <!--del_lnk--> Evgeny Murzin from 1937 to 1957. Only one copy of ANS was built, and it is currently kept at the Lomonosov University in Moscow. In the <!--del_lnk--> 1950s, <!--del_lnk--> RCA produced experimental devices to synthesize both voice and music. The giant <!--del_lnk--> Mark II Music Synthesizer, housed at the <!--del_lnk--> Columbia-Princeton Electronic Music Centre in <a href="../../wp/n/New_York_City.htm" title="New York City">New York City</a> in <!--del_lnk--> 1958, was only capable of producing music once it had been completely programmed. The <!--del_lnk--> vacuum tube system had to be manually patched to create each new type of sound. It used a <!--del_lnk--> paper tape <!--del_lnk--> sequencer punched with holes that controlled pitch sources and filters, similar to a mechanical <!--del_lnk--> player piano but able to generate a wide variety of sounds.<p>In 1958 <!--del_lnk--> Daphne Oram at the <!--del_lnk--> BBC Radiophonic Workshop produced a novel synthesizer using her &quot;<!--del_lnk--> Oramics&quot; technique, driven by drawings on a 35mm film strip. This was used for a number of years at the BBC. <!--del_lnk--> Hugh Le Caine, John Hanert, <!--del_lnk--> Raymond Scott, Percy Grainger (with Burnett Cross), and others built a variety of automated electronic-music controllers during the late 1940s and 1950s.<p>By the <!--del_lnk--> 1960s, synthesizers were developed that could be played in real time but were confined to studios because of their size. These synthesizers were usually configured using a modular design, with standalone signal sources and processors being connected with patch cords or by other means, and all controlled by a common controlling device.<p>Early synthesizers were often experimental special-built devices, usually based on the concept of modularity. <!--del_lnk--> Don Buchla, <!--del_lnk--> Hugh Le Caine, <!--del_lnk--> Raymond Scott and Paul Ketoff were among the first to build such instruments, in the late 1950s and early 1960s. Only <!--del_lnk--> Buchla later produced a commercial version.<p><!--del_lnk--> Robert Moog, who had been a student of <!--del_lnk--> Peter Mauzey, one of the engineers of the RCA Mark II, created a revolutionary synthesizer that could actually be used by pop musicians. Moog designed the circuits used in his synthesizer while he was at Columbia-Princeton. The Moog synthesizer was first displayed at the <!--del_lnk--> Audio Engineering Society convention in <!--del_lnk--> 1964. Like the RCA Mark II, it required a lot of experience to set up the machine for a new sound, but it was smaller and more intuitive. Less like a machine and more like a musical instrument, the Moog synthesizer was at first a curiosity, but by 1968 had caused a sensation.<p><!--del_lnk--> Micky Dolenz of <!--del_lnk--> The Monkees bought one of the first three Moog synthesizers and the first commercial release to feature a Moog synthesizer was <!--del_lnk--> The Monkees&#39; fourth album, <i><!--del_lnk--> Pisces, Aquarius, Capricorn &amp; Jones Ltd.</i>, in 1967, which also became the first album featuring a synthesizer to hit #1 on the charts. Also among the first music performed on this synthesizer was the million-selling <!--del_lnk--> 1968 album <i><!--del_lnk--> Switched-On Bach</i> by <!--del_lnk--> Wendy Carlos. <i>Switched-On Bach</i> was one of the most popular classical-music recordings ever made. During the late 1960s, hundreds of other popular recordings used Moog synthesizer sounds. The Moog synthesizer even spawned a subculture of record producers who made novelty &quot;Moog&quot; recordings, depending on the odd new sounds made by their synthesizers (which were not always Moog units) to draw attention and sales.<p>Moog also established standards for control interfacing, with a logarithmic 1-volt-per-octave pitch control and a separate pulse triggering signal. This standardization allowed synthesizers from different manufacturers to operate together. Pitch control is usually performed either with an organ-style keyboard or a <!--del_lnk--> music sequencer, which produces a series of control voltages over a fixed time period and allows some automation of music production.<p>Other early commercial synthesizer manufacturers included <!--del_lnk--> ARP, who also started with modular synthesizers before producing all-in-one instruments, and British firm <!--del_lnk--> EMS.<p>In 1970, Moog designed an innovative synthesizer with a built-in keyboard and without modular design--the analog circuits were retained, but made interconnectable with switches in a simplified arrangement called &quot;normalization&quot;. Though less flexible than a modular design, it made the instrument more portable and easier to use. This first prepatched synthesizer, the <!--del_lnk--> Minimoog, became very popular, with over 12,000 units sold. The <!--del_lnk--> Minimoog also influenced the design of nearly all subsequent synthesizers.<p>
       <br /> In the 1970s miniaturized solid-state components allowed synthesizers to become self-contained, portable instruments. They began to be used in live performances. Soon, electronic synthesizers had become a standard part of the popular-music repertoire, with Chicory Tip&#39;s &quot;Son of my Father&quot; as the first #1 hit to feature a synthesizer.<p>The first movie to make use of synthesized music was the <a href="../../wp/j/James_Bond.htm" title="James Bond">James Bond</a> film <!--del_lnk--> &quot;On Her Majesty&#39;s Secret Service&quot;, in 1969. From that point on, a large number of movies were made with synthesized music. A few movies, like 1982&#39;s <!--del_lnk--> John Carpenter&#39;s &quot;The Thing&quot;, used all synthesized music in their musical scores.<p><a id="Homemade_synthesizers" name="Homemade_synthesizers"></a><h3> <span class="mw-headline">Homemade synthesizers</span></h3>
      <div class="floatright"><span><a class="image" href="../../images/56/5659.jpg.htm" title=""><img alt="" height="119" longdesc="/wiki/Image:Maplin_5600.jpg" src="../../images/56/5659.jpg" width="199" /></a></span></div>
      <p>During the late 1970s and early 1980s, it was relatively easy to build one&#39;s own synthesizer. Designs were published in hobby electronics magazines (notably the Formant modular synth, an impressive <!--del_lnk--> diy clone of the Moog system, published by Elektur) and complete kits were supplied by companies such as Paia in the US, and Maplin Electronics in the UK (although often these designs were actually rebranded versions of synths originally built by hobbyists, for example, the Maplin 5600 was a creation of the Australian scientist <!--del_lnk--> Trevor Marshall). <a id="Electronic_organs_vs._synthesizers" name="Electronic_organs_vs._synthesizers"></a><h2> <span class="mw-headline">Electronic organs vs. synthesizers</span></h2>
      <p>All organs (including acoustic) are based on the principle of <!--del_lnk--> additive or Fourier Synthesis: Several sine tones are mixed to form a more complex waveform. In the original <!--del_lnk--> Hammond organ, built in 1935, these sine waves were generated using revolving tone wheels which induced a current in an electromagnetic pick-up. For every <!--del_lnk--> harmonic, there had to be a separate <!--del_lnk--> tonewheel. In more modern electronic organs, electronic <!--del_lnk--> oscillators serve to produce the sine waves. Organs tend to use fairly simple &quot;formant&quot; filters to effect changes to the oscillator tone--automation and modulation tend to be limited to simple vibrato.<p>Most analog synthesizers produce their sound using subtractive synthesis. In this method, a waveform rich in overtones, usually a sawtooth or pulse wave, is produced by an oscillator. The signal is then passed through filters, which preferentially remove some overtones to obtain a sound which may be an imitation of an acoustical instrument, or may be a unique tonality not existing in acoustical form. An ADSR envelope generator then controls a VCA (voltage controlled amplifier) to give the sound a loudness contour.<p>Other circuits, such as <!--del_lnk--> waveshapers and <!--del_lnk--> ring modulators, can change the tonality in non-harmonic ways or create <!--del_lnk--> distortion effects which are often not found in natural sound sources. In spite of the popularity of modern digital and software-based synthesizers, the purely analog modular synthesizer still has its proponents, with a number of manufacturers producing modules little different from Moog&#39;s 1964 circuit designs, as well as many newer variations like the Moogalicious 900, invented in 1998.<p><a id="Microprocessor_controlled_and_polyphonic_analog_synthesizers" name="Microprocessor_controlled_and_polyphonic_analog_synthesizers"></a><h2> <span class="mw-headline">Microprocessor controlled and polyphonic analog synthesizers</span></h2>
      <p>Early analog synthesizers were always monophonic, producing only one tone at a time. A few, such as the Moog Sonic Six, <!--del_lnk--> ARP Odyssey and EML 101, were capable of producing two different pitches at a time when two keys were pressed. <!--del_lnk--> Polyphony (multiple simultaneous tones, which enables <!--del_lnk--> chords), was only obtainable with electronic organ designs at first. Popular electronic keyboards combining organ circuits with synthesizer processing included the ARP Omni and Moog&#39;s Polymoog and Opus 3.<p>By 1976, the first true music synthesizers to offer polyphony had begun to appear, most notably in the form of Moog&#39;s <!--del_lnk--> Polymoog, the <!--del_lnk--> Yamaha CS-80 and the Oberheim Four-Voice. These early instruments were very complex, heavy, and costly. Another feature that began to appear was the recording of knob settings in a digital memory, allowing the changing of sounds quickly.<p>When microprocessors first appeared on the scene in the early 1970s, they were expensive and difficult to apply.<p>The first practical polyphonic synth, and the first to use a microprocessor as a controller, was the <!--del_lnk--> Sequential Circuits Prophet-5 introduced in <!--del_lnk--> 1978. For the first time, musicians had a practical polyphonic synthesizer that allowed all knob settings to be saved in computer memory and recalled by pushing a button. The Prophet-5 was also physically compact and lightweight, unlike its predecessors. This basic design paradigm became a standard among synthesizer manufacturers, slowly pushing out the more complex (and more difficult to use) modular design.<p>One of the first real-time polyphonic digital music synthesizers was the <!--del_lnk--> Coupland Digital Music Synthesizer. It was much more portable than a piano but never reached commercial production.<p><a id="MIDI_control" name="MIDI_control"></a><h2> <span class="mw-headline">MIDI control</span></h2>
      <p>Synthesizers became easier to integrate and synchronize with other electronic instruments and controllers with the invention in <!--del_lnk--> 1983 of <!--del_lnk--> MIDI, a <!--del_lnk--> time-coded <!--del_lnk--> serial interface cable. MIDI interfaces are now almost ubiquitous on music equipment, and commonly available on <!--del_lnk--> personal computers (PCs).<p>The so-called <!--del_lnk--> General MIDI (GM) <!--del_lnk--> software standard was devised in <!--del_lnk--> 1991 to serve as a consistent way of describing a set of over 200 tones (including percussion) available to a PC for playback of musical scores. For the first time, a given MIDI preset would consistently produce an oboe or guitar sound (etc.) on any GM-conforming device. The file format <i>.mid</i> was also established and became a popular standard for exchange of music scores between computers.<p><!--del_lnk--> OSC, OpenSound Control, is a proposed replacement for MIDI which was designed for networking. In contrast with MIDI, OSC is fast enough to allow thousands of synthesizers or computers to share music performance data over the internet in realtime.<p><a id="FM_synthesis" name="FM_synthesis"></a><h2> <span class="mw-headline">FM synthesis</span></h2>
      <p><!--del_lnk--> FM Synthesis is when one <!--del_lnk--> oscillator is used to <!--del_lnk--> modulate another <!--del_lnk--> oscillator. This <!--del_lnk--> oscillator can then be used to <!--del_lnk--> modulate another <!--del_lnk--> oscillator or a parameter of the synth or &#39;patch&#39; such as rate, depth, etc. of LFOs (Low Frequency Oscillators). These usually control parameters, but oscillators can modulate the LFOs do give a more complex sound. Oscillators can in turn modulate <b>themselves</b> and produce <!--del_lnk--> White Noise. <!--del_lnk--> John Chowning of <!--del_lnk--> Stanford University is generally considered to be the first researcher to conceive of producing musical sounds by causing one oscillator to modulate the pitch of another. This is called <!--del_lnk--> FM, or frequency modulation, synthesis. Chowning&#39;s early FM experiments were done with software on a mainframe computer.<p>Most FM synthesizers use sine-wave oscillators (called operators) which, in order for their fundamental frequency to be sufficiently stable, are normally generated digitally (several years after Yamaha popularized this field of synthesis, they were outfitted with the ability to generate wavforms other than a sine wave). Each operator&#39;s audio output may be fed to the input of another operator, via an ADSR or other envelope controller. The first operator modulates the pitch of the second operator, in ways that can produce complex waveforms. FM synthesis is fundamentally a type of additive synthesis and the filters used in subtractive synthesizers were typically not used in FM synthesizers until the mid-<!--del_lnk--> 1990s. By cascading operators and programming their envelopes appropriately, some subtractive synthesis effects can be simulated, though the sound of a resonant analog filter is almost impossible to achieve. FM is well-suited for making sounds that subtractive synthesizers have difficulty producing, particularly non-harmonic sounds, such as bell timbres.<p>Chowning&#39;s patent covering FM sound synthesis was licensed to giant Japanese manufacturer <!--del_lnk--> Yamaha, and made millions for Stanford during the <!--del_lnk--> 1980s. Yamaha&#39;s first FM synthesizers, the <!--del_lnk--> GS-1 and <!--del_lnk--> GS-2, were costly and heavy. Keyboardist <!--del_lnk--> Brent Mydland of the <!--del_lnk--> Grateful Dead used a GS-2 extensively in the 1980s. They soon followed the GS series with a pair of smaller, preset versions - the CE20 and CE25 Combo Ensembles <!--del_lnk--> - which were targeted primarily at the home organ market and featured four-octave keyboards. Their third version, the <!--del_lnk--> DX-7 (<!--del_lnk--> 1983), was about the same size and weight as the Prophet-5, was reasonably priced, and depended on custom digital integrated circuits to produce FM tonalities. The DX-7 was a smash hit and can be heard on many recordings from the mid-1980s. Yamaha later licensed its FM technology to other manufacturers. By the time the Stanford patent ran out, almost every personal computer in the world contained an audio input-output system with a built-in 4-operator FM digital synthesizer -- a fact most PC users are not aware of.<p>The GS1 and GS2 had their small memory strips &quot;programmed&quot; by a hardware-based machine that existed only in Hamamatsu (Yamaha Japan headquarters) and Buena Park (Yamaha&#39;s U.S. headquarters). It had four 7&quot; monochrome video monitors, each displaying the parameters of one of the four operators within the GS1/2. At that time a single &quot;operator&quot; was a 14&quot;-square circuit board -- this was of course long before Yamaha condensed the FM circuitry to a single ASIC. Interestingly, what became the DX7&#39;s 4-stage ADSR at that time actually had many break points....about 75 (which proved quite ineffective in modifying sounds, hence the subsequent regress to the analog-synth type ADSR envelope generators).<p>During the time period from 1981-1984, Yamaha built a recording studio on Los Feliz Boulevard in Los Angeles dubbed the &quot;Yamaha R&amp;D Studio&quot;. Besides operating as a commercial recording studio facility, it served as a test area for new musical instrument products sold by what then was called the &quot;Combo&quot; division of Yamaha.<p>The Japanese engineers in Hamamatsu failed to create more than a handful of pleasing sounds for the GS1 with the 4-monitor programming machine, although one of them was used on the recording of &quot;Africa&quot; by Toto. At one point, Mr. John Chowning was invited to try to assist in creating new sounds with FM Synthesis. He came to the Yamaha R&amp;D Studio, and spent a long time trying to make the FM theory result in a useful musical sound in practice. He gave up by the end of the week.<p>Thereafter, a select group of prominent studio synthesists was hired by Yamaha to try to create the voice library for the GS1 (with that same programming tool). They included Gary Leuenberger (who at that time owned an acoustic piano outlet in San Francisco), and Bo Tomlyn (who later founded Key Clique, a third-party DX7 software manufacturer).<p>Between Gary and Bo (and a third programmer hired in the United Kingdom named David Bristow), they created the bulk of the voices for the GS1 and GS2 that really caught the attention of both musicians and musical instrument dealers in the Yamaha channel, through both NAMM (National Association of Music Merchants) demonstrations and in-store demonstrations. Yamaha reports indicated that only 16 GS-1&#39;s were ever produced, and they were all either showcase pieces or donated to Yamaha-sponsored artists, which included (in the U.S.) Stevie Wonder, Toto, Herbie Hancock, and Chick Corea. Despite the fact that it wasn&#39;t actually sold (in the U.S.), the GS-1 bore a retail price of about $16,000, and the GS-2 was priced around $8,000.<p>The CE20 and CE25 &quot;combo ensembles&quot; were sold in the home piano/organ channel in the U.S., but they were accepted to a limited extent in the &quot;professional&quot; music scene. Their sounds were programmed in Japan by some of the engineering staff members who had been working on the GS1 and GS2.<p>The hardware-based FM &quot;programmer&quot; for the CE20/25 was a rack of breadboard electronics about the size of a telephone booth. The first DX7 print brochure distributed around the world included a picture of that programmer.<p>At one time, a young Yamaha engineer was assigned the odious task of listening to real instrument recordings, and trying to emulate them with that crude FM synthesis programmer for the CE20/25&#39;s EPROM&#39;s. That particular engineer was supposedly &quot;locked&quot; in a laboratory for an extended period of time, but eventually failed to produce what the U.S. market thought of as good results in terms of viable synthesizer voices.<p>Despite his difficulties, there were a couple of notable recordings produced in the U.S. utilizing the CE20, including Al Jarreau&#39;s &quot;Mornin&#39;&quot;.<p>Despite a lot of internal pressure from product management within the Yamaha International US division, and all that was going on at the time in terms of the adoption of the MIDI standard by many other companies in the industry, it was decided that the CE20 and CE25 did not need MIDI, since they were relegated to the &quot;home&quot; channel.<p>While all of this was going on, the DX7 development team was working on what would be the most successful Yamaha professional keyboard to date at the Nippon Gakki headquarters in Hamamatsu.<p>They called in the Yamaha International Corporation product managers from the U.S., and held a series of critical meetings in Hamamatsu to review their design concepts.<p>The Nippon Gakki engineering team was headed by &quot;Karl&quot; Hirano. At that time, many of the Japanese engineers who interfaced with US product managers adopted &quot;American&quot; nicknames. Hirano-san selected &quot;Karl&quot; because he liked Karl Malden (who at the time, was on the long-running television show, &quot;Streets of San Francisco&quot; with Michael Douglas.)<p>Key to their design approach during the development stage(1981-82) was that, like the CE20 and CE25, the DX7 should be a &quot;pre-set&quot; synth, with only factory sounds, and no programming capability. Their rationale behind this was the extreme difficulty that the Yamaha team, Bo, Gary, and others had experienced at wielding FM synthesis and the multi-operator algorithms to make good sounds.<p>Luckily, the American product management staff had their way: to make the DX7 (and the relatively unsuccessful DX9) completely programmable instruments. As a result, the DX7 was an unheralded success, literally hundreds of great sounds were created, and an entire industry surrounding 3rd-party sounds was spawned. Further, as mentioned previously, OEM chipsets in PCs with the FM synthesis engine became standard fare in that industry.<p>Many of the preset &quot;General MIDI&quot; sounds in Wintel PCs are exact-DNA clones of numerous sounds originally created by Bo, Gary, Dave Bristow, and a handful of other synthesists. Some even retain the same or similar names that were given them during the DX7 era.<p>When the DX7 was finally introduced in the U.S., Bo Tomlyn, Peter Rochon (from Yamaha Canada) and other Yamaha staff went on the road to show off the product to the North American Yamaha dealer network. Those seminars included what was thought then to be a key element....training the dealers in how to operate and program the DX7. This was a vivid indication that the concern raised in Hamamatsu over the difficulty level of programming the machine had still persisted.<p>But, demand was so high for the DX7 the first year of introduction that a &quot;grey market&quot; influx of units originally purchased in Akihabara and other electronics outlets in Tokyo and other parts of Japan, quickly developed, and that became a serious concern for Yamaha International Corporation management.<p>A rumor was propagated by unknown people at Yamaha (or dealers) that the Japanese units would &quot;blow up&quot; upon being plugged into 120V AC outlets in the U.S., and that the sounds were different from the U.S. version. The latter &quot;rumor&quot; was true. The ROM cartridges included in the Japanese version of the DX7 <b>were</b> different from the American release....the U.S. version had many more of the pleasing sounds created by Bo Tomlyn and Gary Leuenberger.<p>The DX7 exceeded Yamaha&#39;s wildest expectations in terms of unit sales; it took many months for production to catch up with demand. The DX9 failed, most prominently because it was a four-operator (vs six in the DX7) FM and had a cassette tape storage system for voice loading/recording.<p>The rack-mounted TX216 and TX816, although relatively powerful studio instruments at that time, were also poor sellers, due to lack of support and difficult user interface.<p>After the successful introduction of the DX series, Bo Tomlyn, along with Mike Malizola (the original DX-7 Yamaha product manager) and Chuck Monte (founder of Dyno-My-Piano), founded &quot;Key Clique, Inc.&quot;, which sold thousands of ROM cartridges with new FM/DX7 sounds (programmed by Bo) to DX7 owners around the world. Ironically, Key Clique&#39;s &quot;Rhodes-electric-piano&quot; voices led to the relative demise of the Fender Rhodes piano, and even the business started by co-founder Monte (Dyno-My-Piano&#39;s principal product was a Rhodes modification kit). Later, however, Key Clique&#39;s strong dominance in that marketplace was eventually eroded by people &quot;sharing&quot; Tomlyn voice parameter settings over Bulletin Boards on early computers, and many competitors entered the market all at once.<p>The final outcome was not far afield from what the Yamaha engineers had originally been concerned about....the huge library of sounds that propagated throughout the music industry for the FM instruments were actually created by only a handful of synth programmers. In numerous interviews and case studies conducted by Yamaha product management with both retail store owners and keyboardists, it was discovered that the average DX7 purchaser hardly ever wanted...or needed...to program his or her own synthesizer voices, since it was so difficult, and because there were so many great sounds available &quot;off the shelf&quot;.<p>At the time when the FM Synthesis technology was first licensed from Stanford University, just about everyone in management at both Nippon Gakki and Yamaha International in the U.S. thought that FM would be &quot;long-gone&quot; by the time the license ran out (about 1996). That turned out to be completely untrue - witness the flourishing of the technology in the OPL chipsets in the majority of PCs around the world over the past many years (as mentioned previously in this article).<p>The list of prominent musical recordings utilizing the DX7 and the myriad of other FM synthesizers that were introduced later is significant, and new compositions utilizing FM are added to the world music library all the time. Software emulation of the DX7 voice library (including many of the Key Clique sounds) exists today in a wide range of both profssional and &#39;pro-sumer&#39; studio software products.<p><a id="PCM_synthesis" name="PCM_synthesis"></a><h2> <span class="mw-headline">PCM synthesis</span></h2>
      <p>One kind of synthesizer starts with a binary digital recording of an existing sound. This is called a <!--del_lnk--> PCM sample, and is replayed at a range of pitches. Sample playback takes the place of the oscillator found in other synthesizers. The sound is (by most) still processed with synthesizer effects such as filters, LFOs, ring modulators and the like. Most <!--del_lnk--> music workstations use this method of synthesis. Often, the pitch of the sample isn&#39;t changed, but it is simply played back at a faster speed. For example, in order to shift the frequency of a sound one octave higher, it simply needs to be played at double speed. Playing a sample at half speed causes it to be shifted down by one octave, and so on.<p>By contrast, an instrument which primarily records and plays back samples is called a <!--del_lnk--> sampler. If a sample playback instrument neither records samples nor processes samples as a synthesizer, it is a <!--del_lnk--> rompler.<p>Because of the nature of digital sound storage (sound being measured in fractions of time), <!--del_lnk--> anti-aliasing and <!--del_lnk--> interpolation techniques (among others) have to be involved to get a natural sounding waveform as end result - especially if more than one note is being played, and/or if arbitrary tone intervals are used. The calculations on sample-data needs to be of great precision (for high quality, &gt;32bits, more like 64bits at least) especially if a lot of different parameters are needed to make a specific sound: more than a few parameters, a lot of calculations need to be made, to avoid the rounding errors of the different calculations taking place.<p>PCM-sound is obtainable even with a 1-bit system, but the sound is terrible with mostly noise, as there are only two levels, on and off. Since the beginning of PCM synthesis (&lt;1970), almost all number of bits from 1 to 32 have been used, but today the most common ones are 16 and 24bits, going towards 32bits as the next jump up in quality.<p><a id="The_physical_modeling_synthesizer" name="The_physical_modeling_synthesizer"></a><h2> <span class="mw-headline">The physical modeling synthesizer</span></h2>
      <p><!--del_lnk--> Physical modeling synthesis is the synthesis of sound by using a set of equations and algorithms to simulate a physical source of sound. When an initial set of parameters is run through the physical simulation, the simulated sound is generated.<p>Although physical modeling was not a new concept in acoustics and synthesis, it wasn&#39;t until the development of the <!--del_lnk--> Karplus-Strong algorithm, the subsequent refinement and generalization of the algorithm into <!--del_lnk--> digital waveguide synthesis by Julius O. Smith III and others, and the increase in DSP power in the late 1980s that commercial implementations became feasible.<p>Following the success of Yamaha&#39;s licensing of Stanford&#39;s FM synthesis patent, Yamaha signed a contract with Stanford University in <!--del_lnk--> 1989 to jointly develop digital waveguide synthesis. As such, most patents related to the technology are owned by Stanford or Yamaha. A physical modeling synthesizer was first realized commercially with Yamaha&#39;s VL-1, which was released in 1994.<p><a id="The_modern_digital_synthesizer" name="The_modern_digital_synthesizer"></a><h2> <span class="mw-headline">The modern digital synthesizer</span></h2>
      <p>Most modern synthesizers are now completely <!--del_lnk--> digital, including those which model analog synthesis using digital techniques. Digital synthesizers use <!--del_lnk--> digital signal processing (DSP) techniques to make musical sounds. Some digital synthesizers now exist in the form of &#39;<!--del_lnk--> softsynth&#39; software that synthesizes sound using conventional PC hardware. Others use specialized DSP hardware.<p>Digital synthesizers generate a digital sample, corresponding to a sound pressure, at a given sampling frequency (typically 44100 samples per second). In the most basic case, each digital oscillator is modeled by a counter. For each sample, the counter of each oscillator is advanced by an amount that varies depending on the frequency of the oscillator. For harmonic oscillators, the counter indexes a table containing the oscillator&#39;s waveform. For random-noise oscillators, the most significant bits index a table of random numbers. The values indexed by each oscillator&#39;s counter are mixed, processed, and then sent to a digital-to-analog converter, followed by an analog amplifier.<p>To eliminate the difficult multiplication step in the envelope generation and mixing, some synthesizers perform all of the above operations in a logarithmic coding, and add the current ADSR and mix levels to the logarithmic value of the oscillator, to effectively multiply it. To add the values in the last step of mixing, they are converted to linear values.<p><a id="Software-only_synthesis" name="Software-only_synthesis"></a><h2> <span class="mw-headline">Software-only synthesis</span></h2>
      <p>The earliest digital synthesis was performed by <!--del_lnk--> software synthesizers on mainframe computers using methods exactly like those described in digital synthesis, above. Music was coded using punch cards to describe the type of instrument, note and duration. The formants of each timbre were generated as a series of sine waves, converted to fixed-point binary suitable for digital-to-analog converters, and mixed by adding and averaging. The data was written slowly to computer tape and then played back in real time to generate the music.<p>Today, a variety of software is available to run on modern high-speed personal computers. DSP algorithms are commonplace, and permit the creation of fairly accurate simulations of physical acoustic sources or electronic sound generators (oscillators, filters, VCAs, etc). Some commercial programs offer quite lavish and complex models of classic synthesizers--everything from the Yamaha <!--del_lnk--> DX7 to the original Moog modular. Other programs allow the user complete control of all aspects of digital music synthesis, at the cost of greater complexity and difficulty of use.<p><a id="Virtual_Orchestra" name="Virtual_Orchestra"></a><h2> <span class="mw-headline">Virtual Orchestra</span></h2>
      <p>A digital musical instrument, or musical network, capable of simulating the sonic and behavioural characteristics of a traditional acoustic orchestra in real time. The instrument often incorporates various synthesis and sound generating techniques. The <!--del_lnk--> Virtual Orchestra is demarcated from traditional keyboard-based synthesizers due to its live performance capabilities which include the ability to follow a conductor&#39;s tempo and respond to a variety of musical nuances in real time. The instrument&#39;s intelligence is achieved through sophisticated decision making algorithms that utilize knowledge and information from relevant areas of specialization including acoustics, psychoacoustics, music history, and music theory, for example.<p><a id="Commercial_synthesizer_manufacturers" name="Commercial_synthesizer_manufacturers"></a><h2> <span class="mw-headline">Commercial synthesizer manufacturers</span></h2>
      <p>Notable synthesizer manufacturers past and present include:<ul>
       <li><!--del_lnk--> Access Music<li><!--del_lnk--> Alesis<li><!--del_lnk--> ARP<li><!--del_lnk--> Akai<li><!--del_lnk--> Buchla and Associates<li><!--del_lnk--> Casio<li><!--del_lnk--> Clavia<li><!--del_lnk--> Doepfer<li><!--del_lnk--> Electronic Music Studios (EMS)<li><!--del_lnk--> E-mu<li><!--del_lnk--> Ensoniq<li><!--del_lnk--> Fairlight<li><!--del_lnk--> Generalmusic<li><!--del_lnk--> Hartmann Music<li><!--del_lnk--> Kawai<li><!--del_lnk--> Korg<li><!--del_lnk--> Kurzweil Music Systems<li><!--del_lnk--> Moog Music<li><!--del_lnk--> New England Digital (NED)<li><!--del_lnk--> Novation<li><!--del_lnk--> Oberheim<li><!--del_lnk--> PAiA Electronics<li><!--del_lnk--> Palm Products GmbH (PPG)<li><!--del_lnk--> Realtime Music Solutions (RMS)<li><!--del_lnk--> Roland Corporation<li><!--del_lnk--> Sequential Circuits<li><!--del_lnk--> Technics<li><!--del_lnk--> Waldorf Music<li><!--del_lnk--> Yamaha</ul>
      <p>For a more complete list see <!--del_lnk--> Category:Synthesizer manufacturers<p><a id="Classic_synthesizer_designs" name="Classic_synthesizer_designs"></a><h2> <span class="mw-headline">Classic synthesizer designs</span></h2>
      <p><i>This is intended to be a list of classic instruments which marked a turning point in musical sound or style, potentially worth an article of their own. They are listed with the names of performers or styles associated with them. For more synthesizer models see <!--del_lnk--> Category:Synthesizers.</i><ul>
       <li><!--del_lnk--> Alesis Andromeda (A synthesizer with modern digital control of fully analog sound producing circuitry)<li><!--del_lnk--> ARP 2600 (<!--del_lnk--> The Who, <!--del_lnk--> Stevie Wonder, <!--del_lnk--> Weather Report, <!--del_lnk--> Edgar Winter, <!--del_lnk--> Jean-Michel Jarre, <!--del_lnk--> New Order)<li><!--del_lnk--> ARP Odyssey (<!--del_lnk--> Ultravox and their former frontman <!--del_lnk--> John Foxx, <!--del_lnk--> Styx, <!--del_lnk--> Herbie Hancock)<li><!--del_lnk--> Buchla Music Box (<!--del_lnk--> Morton Subotnick, <!--del_lnk--> Suzanne Ciani)<li><!--del_lnk--> Casio CZ-101 An early low-cost digital synthesizer (<!--del_lnk--> Vince Clarke)<li><!--del_lnk--> Casio VL-1 More famous for it&#39;s drum beat than its synthesizer sounds. Trio&#39;s Da Da Da.<li><!--del_lnk--> Clavia Nord Lead (<!--del_lnk--> God Lives Underwater, <!--del_lnk--> Zoot Woman, <!--del_lnk--> The Weathermen, <!--del_lnk--> Jean Michel Jarre, the first modern analog modelling synthesizer using digital circuitry to emulate analog circuits)<li><!--del_lnk--> EMS VCS3 (<!--del_lnk--> Roxy Music, <!--del_lnk--> Hawkwind, <!--del_lnk--> Pink Floyd, <!--del_lnk--> BBC Radiophonic Workshop, <!--del_lnk--> Brian Eno)<li><!--del_lnk--> E-mu Emulator (<!--del_lnk--> The Residents, <!--del_lnk--> Depeche Mode, <!--del_lnk--> Deep Purple, <!--del_lnk--> Genesis)<li><!--del_lnk--> Fairlight CMI (<!--del_lnk--> Jean-Michel Jarre, <!--del_lnk--> Jan Hammer, <!--del_lnk--> Peter Gabriel, <!--del_lnk--> Mike Oldfield, <!--del_lnk--> Pet Shop Boys, <!--del_lnk--> The Art of Noise, <!--del_lnk--> Kate Bush)<li><!--del_lnk--> Hartmann Music Neuron (<!--del_lnk--> Hans Zimmer, <!--del_lnk--> Peter Gabriel, <!--del_lnk--> Guns &#39;n Roses, <!--del_lnk--> Nikos Patrelakis, <!--del_lnk--> David Sylvian)<li><!--del_lnk--> Korg Karma<li><!--del_lnk--> Korg M1 (<!--del_lnk--> Bradley Joseph)<li><!--del_lnk--> Korg Triton (<!--del_lnk--> Bradley Joseph, <!--del_lnk--> Derek Sherinian}<li><!--del_lnk--> Kurzweil K2000 Synthesizer with V.A.S.T system (<!--del_lnk--> Jean Michel Jarre )<li><!--del_lnk--> Lyricon First mass-produced wind synthesizer. (<!--del_lnk--> Michael Brecker, <!--del_lnk--> Tom Scott, <!--del_lnk--> Chuck Greenberg, <!--del_lnk--> Wayne Shorter)<li><!--del_lnk--> Moog modular synthesizer (<!--del_lnk--> Rush [pedals only], <!--del_lnk--> Wendy Carlos, <!--del_lnk--> Tomita, <!--del_lnk--> Tonto&#39;s Expanding Head Band, <!--del_lnk--> Emerson, Lake and Palmer, <a href="../../wp/t/The_Beatles.htm" title="The Beatles">The Beatles</a>,<!--del_lnk--> Weezer)<li><!--del_lnk--> Moog Taurus (<!--del_lnk--> Rush, <!--del_lnk--> Genesis, <!--del_lnk--> The Police, <a href="../../wp/u/U2.htm" title="U2">U2</a>, <!--del_lnk--> The Rentals)<li><!--del_lnk--> Minimoog (<!--del_lnk--> Pink Floyd, <!--del_lnk--> Rush, <!--del_lnk--> Yes, <!--del_lnk--> Emerson Lake and Palmer, <!--del_lnk--> Stereolab, <!--del_lnk--> Devo, <!--del_lnk--> Ray Buttigieg, <!--del_lnk--> George Duke)<li><!--del_lnk--> NED Synclavier (<!--del_lnk--> Michael Jackson, <!--del_lnk--> Stevie Wonder, <!--del_lnk--> Laurie Anderson, <!--del_lnk--> Frank Zappa, <!--del_lnk--> Pat Metheny Group)<li><!--del_lnk--> Oberheim OB-Xa (<!--del_lnk--> Rush, <!--del_lnk--> Prince, <!--del_lnk--> Styx, <!--del_lnk--> Supertramp, <a href="../../wp/v/Van_Halen.htm" title="Van Halen">Van Halen</a>)<li><!--del_lnk--> PPG Wave (<!--del_lnk--> Rush, <!--del_lnk--> Depeche Mode, <!--del_lnk--> The Fixx, <!--del_lnk--> Thomas Dolby)<li><!--del_lnk--> Roland D-50 (<!--del_lnk--> Jean-Michel Jarre, <!--del_lnk--> Enya)<li><!--del_lnk--> Roland JD-800 (<!--del_lnk--> Bradley Joseph)<li><!--del_lnk--> Roland JP-8000<li><!--del_lnk--> Roland Jupiter-4 (<!--del_lnk--> a-ha,<!--del_lnk--> John Foxx, <a href="../../wp/d/Duran_Duran.htm" title="Duran Duran">Duran Duran</a>, <!--del_lnk--> The Human League, <!--del_lnk--> Simple Minds)<li><!--del_lnk--> Roland Jupiter-8 (<!--del_lnk--> a-ha,<!--del_lnk--> Rush, <a href="../../wp/d/Duran_Duran.htm" title="Duran Duran">Duran Duran</a>, <!--del_lnk--> OMD, <!--del_lnk--> Huey Lewis &amp; the News)<li><!--del_lnk--> Roland MT-32 (de-facto standard in <!--del_lnk--> computer game music and effects)<li><!--del_lnk--> Roland TB-303 (<!--del_lnk--> Techno, <!--del_lnk--> Acid House)<li><!--del_lnk--> Sequential Circuits Prophet 5 (<!--del_lnk--> Berlin, <!--del_lnk--> Phil Collins, <!--del_lnk--> The Cars, <!--del_lnk--> Steve Winwood)<li><!--del_lnk--> WaveFrame AudioFrame (<!--del_lnk--> Peter Gabriel, <!--del_lnk--> Stevie Wonder)<li><!--del_lnk--> Yamaha DX7 (<!--del_lnk--> Rush, <!--del_lnk--> Steve Reich, <!--del_lnk--> Depeche Mode, <!--del_lnk--> Zoot Woman, <!--del_lnk--> The Cure, <!--del_lnk--> Brian Eno, <!--del_lnk--> Howard Jones, <!--del_lnk--> Nitzer Ebb)<li><!--del_lnk--> Yamaha CS-2<li><!--del_lnk--> Yamaha SHS-10 One of the first &quot;<!--del_lnk--> keytars&quot; from the 1980s (<!--del_lnk--> Showbread (band))</ul>
      <p><a id="See_also" name="See_also"></a><div class="printfooter"> Retrieved from &quot;<!--del_lnk--> http://en.wikipedia.org/wiki/Synthesizer&quot;</div>
      <!-- end content -->
      <div class="visualClear">
      </div>
     </div>
    </div>
   </div>
   <!-- end of the left (by default at least) column -->
   <div class="visualClear">
   </div>
   <div id="footer">
    <div class="center"> This reference article is mainly selected from the English Wikipedia with only minor checks and changes (see www.wikipedia.org for details of authors and sources) and is available under the <nobr><a href="../../wp/w/Wikipedia_Text_of_the_GNU_Free_Documentation_License.htm">GNU Free Documentation License</a></nobr>. See also our <b><a href="../../disclaimer.htm">Disclaimer</a></b>. </div>
   </div>
   <script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
  </div>
  
 </body>
</html>
